{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 部署与维护"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.21\n",
      "chromadb                                 0.6.3\n",
      "cryptography                             44.0.2\n",
      "duckduckgo_search                        7.5.3\n",
      "langchain                                0.3.21\n",
      "langchain-community                      0.3.20\n",
      "langchain-core                           0.3.47\n",
      "langchain-deepseek                       0.1.3\n",
      "langchain-experimental                   0.3.4\n",
      "langchain-openai                         0.3.9\n",
      "langchain-text-splitters                 0.3.7\n",
      "numpy                                    2.0.2\n",
      "openai                                   1.68.2\n",
      "scipy                                    1.10.1\n",
      "tiktoken                                 0.9.0\n",
      "unstructured                             0.17.2\n",
      "unstructured-client                      0.31.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from IPython.display import Markdown\n",
    "from setenv import APIKeyManager\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "# 设置API密钥\n",
    "key_manager = APIKeyManager().setup_api_key([\"DEEPSEEK_API_KEY\"])\n",
    "\n",
    "# 查看Python版本\n",
    "!python -V\n",
    "# 查看安装的库\n",
    "!pip list | grep -E 'langchain|openai|llm|tiktoken|chromadb|cryptography|duck|unstructured|numpy|scipy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 应用部署"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 API服务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class Query(BaseModel):\n",
    "    text: str\n",
    "\n",
    "@app.post(\"/generate\")\n",
    "async def generate(query: Query):\n",
    "    try:\n",
    "        logger.info(f\"收到请求: {query.text}\")\n",
    "        llm = ChatDeepSeek(model='deepseek-chat')\n",
    "        prompt = PromptTemplate(\n",
    "            template=\n",
    "            \"\"\"\n",
    "            结果使用中英两种语言回答\n",
    "            问题: {question}\n",
    "            \"\"\",\n",
    "            input_variables=['question']\n",
    "        )\n",
    "        chain = prompt | llm\n",
    "        response = chain.invoke(query.text)\n",
    "        logger.info(\"请求处理成功\")\n",
    "        return {\"response\": response}\n",
    "    except Exception as e:\n",
    "        error_msg = f\"处理请求时发生错误: {str(e)}\"\n",
    "        logger.error(error_msg)\n",
    "        raise HTTPException(status_code=500, detail=error_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [104947]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import uvicorn\n",
    "import asyncio\n",
    "import uvloop\n",
    "from threading import Thread\n",
    "\n",
    "# 在后台线程中启动服务\n",
    "def start_server():  \n",
    "    # Use standard asyncio event loop instead of uvloop  \n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, loop=\"asyncio\")  \n",
    "\n",
    "# 启动服务器 \n",
    "server_thread = Thread(target=start_server)\n",
    "server_thread.daemon = True  # 设置为守护线程，这样当Jupyter关闭时线程会自动结束\n",
    "server_thread.start()\n",
    "\n",
    "# 等待服务器启动\n",
    "time.sleep(3)  # 增加等待时间，确保服务器完全启动\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:19:06,211 - __main__ - INFO - 收到请求: 讲解一下LangChain的主要功能\n",
      "2025-03-25 12:19:06,355 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-03-25 12:19:27,849 - __main__ - INFO - 请求处理成功\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:54756 - \"POST /generate HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API响应结果:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**LangChain的主要功能**  \n",
       "\n",
       "**1. 模块化组件（Modular Components）**  \n",
       "提供预构建的模块（如模型调用、记忆管理、数据检索等），支持灵活组合以构建复杂应用。  \n",
       "\n",
       "**2. 模型集成（Model Integration）**  \n",
       "支持多种大语言模型（如OpenAI、Anthropic、Hugging Face等），统一接口简化调用流程。  \n",
       "\n",
       "**3. 数据增强检索（Retrieval-Augmented Generation, RAG）**  \n",
       "结合外部数据源（如文档、数据库），通过检索增强生成内容的准确性和相关性。  \n",
       "\n",
       "**4. 记忆管理（Memory）**  \n",
       "支持短期（会话级）和长期（数据库）记忆存储，维持多轮对话的上下文连贯性。  \n",
       "\n",
       "**5. 代理与工具链（Agents & Tools）**  \n",
       "允许模型通过工具（如搜索、计算）与外部系统交互，实现动态任务执行（如自动网页搜索、API调用）。  \n",
       "\n",
       "**6. 链式工作流（Chains）**  \n",
       "将多个模块串联成自动化流程（如“提问→检索→生成”），适用于复杂任务编排。  \n",
       "\n",
       "**7. 评估与调试（Evaluation）**  \n",
       "提供工具评估模型输出效果，帮助优化提示（prompt）和流程设计。  \n",
       "\n",
       "---  \n",
       "\n",
       "**Main Features of LangChain**  \n",
       "\n",
       "**1. Modular Components**  \n",
       "Pre-built modules (e.g., model calls, memory, data retrieval) enable flexible assembly of complex applications.  \n",
       "\n",
       "**2. Model Integration**  \n",
       "Unified interface for multiple LLMs (OpenAI, Anthropic, Hugging Face, etc.), simplifying model calls.  \n",
       "\n",
       "**3. Retrieval-Augmented Generation (RAG)**  \n",
       "Enhances responses by integrating external data (documents, databases) into generation.  \n",
       "\n",
       "**4. Memory Management**  \n",
       "Supports short-term (conversation) and long-term (database) memory to maintain context.  \n",
       "\n",
       "**5. Agents & Tools**  \n",
       "Models interact with external systems via tools (e.g., search, APIs) for dynamic task execution.  \n",
       "\n",
       "**6. Chains**  \n",
       "Automates multi-step workflows (e.g., \"question→retrieve→generate\") for complex tasks.  \n",
       "\n",
       "**7. Evaluation**  \n",
       "Tools to assess output quality and optimize prompts/pipelines."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # 调用API示例\n",
    "    url = \"http://localhost:8000/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    data = {\"text\": \"讲解一下LangChain的主要功能\"}\n",
    "    # \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    print(\"API响应结果:\")\n",
    "    display(Markdown(response.json()['response']['content']))\n",
    "except Exception as e:\n",
    "    print(f\"请求发生错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 监控与维护"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 性能监控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def monitor_performance():\n",
    "    with get_openai_callback() as cb:\n",
    "        response = chain.run(input)\n",
    "        print(f\"Token使用量: {cb.total_tokens}\")\n",
    "        print(f\"API调用次数: {cb.successful_requests}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:30:07,402 - httpx - INFO - HTTP Request: POST https://api.deepseek.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查询: 解释一下向量数据库的作用\n",
      "Token使用量: 756\n",
      "API调用次数: 1\n",
      "总花费: $0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "# 演示性能监控\n",
    "input_text = \"解释一下向量数据库的作用\"\n",
    "with get_openai_callback() as cb:\n",
    "    chain = ChatDeepSeek(model='deepseek-chat')\n",
    "    response = chain.invoke(input_text)\n",
    "    print(f\"查询: {input_text}\")\n",
    "    print(f\"Token使用量: {cb.total_tokens}\")\n",
    "    print(f\"API调用次数: {cb.successful_requests}\")\n",
    "    print(f\"总花费: ${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "向量数据库（Vector Database）是一种专门用于存储、检索和管理**向量数据（高维数值数组）**的数据库系统。它的核心作用是高效处理基于向量相似度的搜索和分析，广泛应用于机器学习、人工智能和大数据领域。以下是其核心作用及关键特点的详细解释：\n",
       "\n",
       "---\n",
       "\n",
       "### **1. 核心作用**\n",
       "#### （1）**相似性搜索**\n",
       "   - **问题场景**：给定一个查询向量（如图片、文本的嵌入表示），快速找到数据库中与之最相似的向量。\n",
       "   - **解决方案**：通过计算向量间的距离（如余弦相似度、欧氏距离），返回最接近的结果。\n",
       "   - **典型应用**：\n",
       "     - 图片/视频检索（如以图搜图）。\n",
       "     - 推荐系统（相似商品、用户兴趣匹配）。\n",
       "     - 自然语言处理（语义搜索、问答系统）。\n",
       "\n",
       "#### （2）**高效存储与索引**\n",
       "   - 传统数据库无法高效处理高维向量，而向量数据库使用**近似最近邻（ANN）算法**（如HNSW、IVF、LSH）加速搜索，在精度和速度间取得平衡。\n",
       "   - 支持海量向量数据的持久化存储和实时更新。\n",
       "\n",
       "#### （3）**多模态数据处理**\n",
       "   - 可将不同模态（文本、图像、音频）转换为统一向量空间，实现跨模态搜索（如用文本搜索图片）。\n",
       "\n",
       "#### （4）**AI模型集成**\n",
       "   - 作为AI应用的底层基础设施，存储模型生成的嵌入向量（Embeddings），支撑模型推理和微调。\n",
       "\n",
       "---\n",
       "\n",
       "### **2. 关键特点**\n",
       "- **高维索引**：优化数十到数千维向量的检索效率。\n",
       "- **实时性**：支持低延迟查询，适合在线服务（如聊天机器人）。\n",
       "- **可扩展性**：分布式架构支持水平扩展，应对亿级数据。\n",
       "- **混合查询**：结合向量搜索与传统结构化查询（如过滤标签+相似性搜索）。\n",
       "\n",
       "---\n",
       "\n",
       "### **3. 与传统数据库对比**\n",
       "| **能力**               | **传统数据库**       | **向量数据库**               |\n",
       "|------------------------|---------------------|-----------------------------|\n",
       "| 数据类型               | 结构化数据（表格）   | 高维向量+结构化元数据         |\n",
       "| 查询方式               | 精确匹配（SQL）      | 相似性搜索（距离计算）        |\n",
       "| 索引优化               | B树、哈希索引        | ANN算法（HNSW、IVF等）       |\n",
       "| 典型场景               | 交易记录、用户管理   | 推荐系统、语义搜索            |\n",
       "\n",
       "---\n",
       "\n",
       "### **4. 典型应用场景**\n",
       "- **推荐系统**：根据用户历史行为向量推荐相似内容。\n",
       "- **AIGC**：存储生成式AI的嵌入，实现个性化生成（如Diffusion模型检索）。\n",
       "- **异常检测**：通过向量距离识别异常数据（如金融欺诈）。\n",
       "- **生物信息学**：基因序列相似性分析。\n",
       "\n",
       "---\n",
       "\n",
       "### **5. 常见工具**\n",
       "- **专用向量数据库**：Milvus、Pinecone、Weaviate、Qdrant。\n",
       "- **扩展向量功能的数据库**：PostgreSQL（pgvector）、Redis（RedisSearch）。\n",
       "- **云服务**：Google Vertex AI Matching Engine、AWS Aurora ML。\n",
       "\n",
       "---\n",
       "\n",
       "### **总结**\n",
       "向量数据库通过优化高维向量的存储和检索，解决了AI时代非结构化数据（如图片、文本）的相似性搜索难题，成为构建智能应用的关键组件。其核心价值在于**将复杂的语义匹配转化为高效的数学计算**，从而释放数据的深层关联性。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
