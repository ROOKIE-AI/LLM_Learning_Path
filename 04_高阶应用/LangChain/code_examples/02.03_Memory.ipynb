{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4077.16s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4082.35s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromadb                                 0.6.3\n",
      "cryptography                             44.0.2\n",
      "duckduckgo_search                        7.5.3\n",
      "langchain                                0.3.21\n",
      "langchain-community                      0.3.20\n",
      "langchain-core                           0.3.47\n",
      "langchain-deepseek                       0.1.3\n",
      "langchain-openai                         0.3.9\n",
      "langchain-text-splitters                 0.3.7\n",
      "openai                                   1.68.2\n",
      "tiktoken                                 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from IPython.display import Markdown\n",
    "from setenv import APIKeyManager\n",
    "\n",
    "# å¿½ç•¥è­¦å‘Š\n",
    "warnings.filterwarnings('ignore')\n",
    "# è®¾ç½®APIå¯†é’¥\n",
    "key_manager = APIKeyManager().setup_api_key(env_names=[\"OPENAI_API_KEY\", \"OPENAI_API_BASE\"])\n",
    "\n",
    "# !pip install chromadb\n",
    "# !pip install langchain-deepseek\n",
    "\n",
    "# æŸ¥çœ‹Pythonç‰ˆæœ¬\n",
    "!python -V\n",
    "# æŸ¥çœ‹å®‰è£…çš„åº“\n",
    "!pip list | grep -E 'langchain|openai|llm|tiktoken|chromadb|cryptography|duck'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. è®°å¿†ç±»å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 BufferMemory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationBufferMemory æ˜¯æœ€ç®€å•çš„è®°å¿†ç±»å‹ï¼Œå®ƒå°†æ‰€æœ‰å¯¹è¯å†å²å­˜å‚¨åœ¨åˆ—è¡¨ä¸­<br/>\n",
    "memory_key å‚æ•°æŒ‡å®šåœ¨é“¾çš„è¾“å…¥ä¸­ä½¿ç”¨å“ªä¸ªé”®æ¥å­˜å‚¨å¯¹è¯å†å²<br/>\n",
    "return_messages=True è¡¨ç¤ºè¿”å›æ¶ˆæ¯å¯¹è±¡åˆ—è¡¨è€Œä¸æ˜¯å­—ç¬¦ä¸²<br/>\n",
    "è¿™ç§è®°å¿†ç±»å‹é€‚åˆçŸ­å¯¹è¯ï¼Œä½†å¯¹äºé•¿å¯¹è¯å¯èƒ½ä¼šå ç”¨è¿‡å¤šå†…å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58988/1975669923.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n",
      "/tmp/ipykernel_58988/1975669923.py:22: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# åˆ›å»ºLLM\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"deepseek-chat\")\n",
    "\n",
    "# åˆ›å»ºç¼“å†²è®°å¿†\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # æŒ‡å®šè®°å¿†åœ¨é“¾è¾“å…¥ä¸­çš„é”®å\n",
    "    return_messages=True        # è¿”å›æ¶ˆæ¯å¯¹è±¡è€Œéå­—ç¬¦ä¸²\n",
    ")\n",
    "\n",
    "# åˆ›å»ºæç¤ºæ¨¡æ¿\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"input\"],\n",
    "    template=\"èŠå¤©å†å²ï¼š{chat_history}\\nç”¨æˆ·è¾“å…¥ï¼š{input}\\nå›ç­”ï¼š\"\n",
    ")\n",
    "\n",
    "# åœ¨é“¾ä¸­ä½¿ç”¨\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜ã€‚',\n",
       " 'chat_history': [HumanMessage(content='ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜ã€‚', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï½ğŸ˜Š ä»Šå¤©æœ‰ä»€ä¹ˆæƒ³èŠçš„è¯é¢˜å—ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å‘¢ï¼Ÿ', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï½ğŸ˜Š ä»Šå¤©æœ‰ä»€ä¹ˆæƒ³èŠçš„è¯é¢˜å—ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å‘¢ï¼Ÿ'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜ã€‚\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'æˆ‘æ˜¯Rookie',\n",
       " 'chat_history': [HumanMessage(content='ä½ å¥½ï¼Œæˆ‘æ˜¯å°æ˜ã€‚', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='ä½ å¥½ï¼Œå°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï½ğŸ˜Š ä»Šå¤©æœ‰ä»€ä¹ˆæƒ³èŠçš„è¯é¢˜å—ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å‘¢ï¼Ÿ', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='æˆ‘æ˜¯Rookie', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='ä½ å¥½ï¼ŒRookieï¼çœ‹æ¥ä½ æ¢äº†ä¸ªæ–°åå­—å‘¢ï½âœ¨ ä¹‹å‰çš„å°æ˜æ˜¯æ˜µç§°å—ï¼Ÿè¿˜æ˜¯ç°åœ¨æƒ³ç”¨Rookieè¿™ä¸ªåå­—æ¥èŠå¤©å‘¢ï¼Ÿ  \\n\\næ— è®ºæ€æ ·ï¼Œéƒ½å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜„ ä»Šå¤©æƒ³èŠèŠä»€ä¹ˆï¼Ÿæ¸¸æˆã€ç”Ÿæ´»ï¼Œè¿˜æ˜¯æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„è¯é¢˜ï¼Ÿ', additional_kwargs={}, response_metadata={})],\n",
       " 'text': 'ä½ å¥½ï¼ŒRookieï¼çœ‹æ¥ä½ æ¢äº†ä¸ªæ–°åå­—å‘¢ï½âœ¨ ä¹‹å‰çš„å°æ˜æ˜¯æ˜µç§°å—ï¼Ÿè¿˜æ˜¯ç°åœ¨æƒ³ç”¨Rookieè¿™ä¸ªåå­—æ¥èŠå¤©å‘¢ï¼Ÿ  \\n\\næ— è®ºæ€æ ·ï¼Œéƒ½å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ğŸ˜„ ä»Šå¤©æƒ³èŠèŠä»€ä¹ˆï¼Ÿæ¸¸æˆã€ç”Ÿæ´»ï¼Œè¿˜æ˜¯æœ‰ä»€ä¹ˆç‰¹åˆ«æ„Ÿå…´è¶£çš„è¯é¢˜ï¼Ÿ'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"æˆ‘æ˜¯Rookie\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 VectorStoreMemory\n",
    "VectorStoreMemory ä½¿ç”¨å‘é‡å­˜å‚¨æ¥ä¿å­˜å¯¹è¯å†å²ï¼Œé€‚åˆé•¿å¯¹è¯å’Œè¯­ä¹‰æœç´¢<br/>\n",
    "å®ƒå¯ä»¥æ ¹æ®å½“å‰æŸ¥è¯¢æ£€ç´¢ç›¸å…³çš„å†å²å¯¹è¯ï¼Œè€Œä¸æ˜¯ç®€å•åœ°è¿”å›æ‰€æœ‰å†å²<br/>\n",
    "è¿™ç§è®°å¿†ç±»å‹ç‰¹åˆ«é€‚åˆéœ€è¦ä»å¤§é‡å†å²å¯¹è¯ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯çš„åœºæ™¯<br/>\n",
    "ä¸‹é¢æ˜¯ä¸€ä¸ªç®€å•çš„VectorStoreMemoryç¤ºä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings  \n",
    "from langchain_community.vectorstores import FAISS  \n",
    "import tempfile  \n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "\n",
    "# ç”±äºæ²¡æœ‰langchain_deepseek.embeddingsæ¨¡å—ï¼Œæˆ‘ä»¬ä½¿ç”¨OpenAIåµŒå…¥\n",
    "# ä½†é…ç½®ä¸ºä½¿ç”¨deepseekæ¨¡å‹ï¼ˆå¦‚æœAPIæ”¯æŒï¼‰\n",
    "embeddings = OpenAIEmbeddings(  \n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    model=\"text-embedding-ada-002\"  # è¿™é‡Œä½¿ç”¨OpenAIçš„åµŒå…¥æ¨¡å‹ï¼Œå®é™…ä½¿ç”¨æ—¶å¯æ›¿æ¢ä¸ºæ”¯æŒçš„deepseekåµŒå…¥æ¨¡å‹\n",
    ")  \n",
    "\n",
    "# åˆ›å»ºä¸´æ—¶ç›®å½•æ¥å­˜å‚¨FAISSç´¢å¼•  \n",
    "persist_directory = tempfile.mkdtemp()  \n",
    "\n",
    "# ä½¿ç”¨FAISSåˆ›å»ºå‘é‡å­˜å‚¨  \n",
    "vectorstore = FAISS.from_texts(  \n",
    "    [\"åˆå§‹åŒ–å‘é‡å­˜å‚¨\"],   \n",
    "    embedding=embeddings  \n",
    ")  \n",
    "\n",
    "# åˆ›å»ºè®°å¿†ç»„ä»¶  \n",
    "memory = VectorStoreRetrieverMemory(  \n",
    "    retriever=vectorstore.as_retriever(),  \n",
    "    memory_key=\"chat_history\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‘è®°å¿†ä¸­æ·»åŠ ä¸€äº›ç¤ºä¾‹å¯¹è¯\n",
    "# æ³¨æ„ï¼šç”±äºå‡ºç°NotFoundError: Error code: 404é”™è¯¯ï¼Œ\n",
    "# å¯èƒ½æ˜¯å‘é‡å­˜å‚¨é…ç½®æœ‰é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦é‡æ–°åˆå§‹åŒ–å‘é‡å­˜å‚¨\n",
    "# ç¡®ä¿å‘é‡å­˜å‚¨æ­£ç¡®åˆ›å»ºå¹¶æŒä¹…åŒ–åˆ°ç£ç›˜\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªæœ¬åœ°æŒä¹…åŒ–çš„å‘é‡å­˜å‚¨\n",
    "\n",
    "\n",
    "# ç°åœ¨å°è¯•ä¿å­˜ä¸Šä¸‹æ–‡\n",
    "memory.save_context(\n",
    "    {\"input\": \"æˆ‘æœ€å–œæ¬¢çš„é¢œè‰²æ˜¯è“è‰²\"},\n",
    "    {\"output\": \"è“è‰²æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„é¢œè‰²ï¼å®ƒè®©äººè”æƒ³åˆ°æµ·æ´‹å’Œå¤©ç©ºã€‚\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"æˆ‘å–œæ¬¢åœ¨å‘¨æœ«å»çˆ¬å±±\"},\n",
    "    {\"output\": \"çˆ¬å±±æ˜¯ä¸€é¡¹å¾ˆå¥½çš„æ´»åŠ¨ï¼Œæ—¢èƒ½é”»ç‚¼èº«ä½“åˆèƒ½äº²è¿‘è‡ªç„¶ã€‚\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"æˆ‘å…»äº†ä¸€åªå«å°èŠ±çš„çŒ«\"},\n",
    "    {\"output\": \"å°èŠ±æ˜¯ä¸ªå¯çˆ±çš„åå­—ï¼çŒ«å’ªæ˜¯å¾ˆå¥½çš„å® ç‰©ä¼´ä¾£ã€‚\"}\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ï¼Œèƒ½å¤Ÿè®°ä½ç”¨æˆ·ä¹‹å‰æåˆ°çš„ä¿¡æ¯ã€‚\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"human\", \"ç›¸å…³çš„å¯¹è¯å†å²ï¼š\\n{chat_history}\")\n",
    "])\n",
    "\n",
    "# åˆ›å»ºé“¾\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"deepseek-chat\")\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# æµ‹è¯•å‘é‡å­˜å‚¨è®°å¿†\n",
    "response = chain.invoke({\"input\": \"æˆ‘ä¹‹å‰è¯´è¿‡æˆ‘å–œæ¬¢ä»€ä¹ˆé¢œè‰²ï¼Ÿ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
