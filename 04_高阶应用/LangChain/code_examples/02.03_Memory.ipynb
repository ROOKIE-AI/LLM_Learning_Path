{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from IPython.display import Markdown\n",
    "from setenv import APIKeyManager\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "# 设置API密钥\n",
    "key_manager = APIKeyManager().setup_api_key(env_names=[\"OPENAI_API_KEY\", \"OPENAI_API_BASE\"])\n",
    "\n",
    "# !pip install chromadb\n",
    "# !pip install langchain-deepseek\n",
    "\n",
    "# 查看Python版本\n",
    "!python -V\n",
    "# 查看安装的库\n",
    "!pip list | grep -E 'langchain|openai|llm|tiktoken|chromadb|cryptography|duck'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 记忆类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 BufferMemory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationBufferMemory 是最简单的记忆类型，它将所有对话历史存储在列表中<br/>\n",
    "memory_key 参数指定在链的输入中使用哪个键来存储对话历史<br/>\n",
    "return_messages=True 表示返回消息对象列表而不是字符串<br/>\n",
    "这种记忆类型适合短对话，但对于长对话可能会占用过多内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 创建LLM\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"deepseek-chat\")\n",
    "\n",
    "# 创建缓冲记忆\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 指定记忆在链输入中的键名\n",
    "    return_messages=True        # 返回消息对象而非字符串\n",
    ")\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"input\"],\n",
    "    template=\"聊天历史：{chat_history}\\n用户输入：{input}\\n回答：\"\n",
    ")\n",
    "\n",
    "# 在链中使用\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"你好，我是小明。\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke({\"input\": \"我是Rookie\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 VectorStoreMemory\n",
    "VectorStoreMemory 使用向量存储来保存对话历史，适合长对话和语义搜索<br/>\n",
    "它可以根据当前查询检索相关的历史对话，而不是简单地返回所有历史<br/>\n",
    "这种记忆类型特别适合需要从大量历史对话中检索相关信息的场景<br/>\n",
    "下面是一个简单的VectorStoreMemory示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import requests  \n",
    "from langchain.embeddings.base import Embeddings  \n",
    "from langchain_community.vectorstores import FAISS  \n",
    "import tempfile  \n",
    "from langchain.memory import VectorStoreRetrieverMemory  \n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 自定义DeepSeek嵌入类  \n",
    "class DeepSeekEmbeddings(Embeddings):  \n",
    "    def __init__(self, api_key):  \n",
    "        self.api_key = api_key  \n",
    "    \n",
    "    def embed_documents(self, texts):  \n",
    "        headers = {  \n",
    "            'Authorization': f'Bearer {self.api_key}',  \n",
    "            'Content-Type': 'application/json'  \n",
    "        }  \n",
    "        response = requests.post(  \n",
    "            'https://api.deepseek.com/embeddings',  \n",
    "            json={'input': texts, 'model': 'deepseek-embed'},  \n",
    "            headers=headers  \n",
    "        )  \n",
    "        response.raise_for_status()  \n",
    "        return [item['embedding'] for item in response.json()['data']]\n",
    "    \n",
    "    def embed_query(self, text):  \n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "embeddings = DeepSeekEmbeddings(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# 创建临时目录来存储FAISS索引  \n",
    "persist_directory = tempfile.mkdtemp()  \n",
    "\n",
    "# 使用FAISS创建向量存储  \n",
    "vectorstore = FAISS.from_texts(  \n",
    "    [\"初始化向量存储\"],   \n",
    "    embedding=embeddings  \n",
    ")  \n",
    "\n",
    "# 创建记忆组件  \n",
    "memory = VectorStoreRetrieverMemory(  \n",
    "    retriever=vectorstore.as_retriever(),  \n",
    "    memory_key=\"chat_history\"  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向记忆中添加一些示例对话\n",
    "# 注意：由于出现NotFoundError: Error code: 404错误，\n",
    "# 可能是向量存储配置有问题，我们需要重新初始化向量存储\n",
    "# 确保向量存储正确创建并持久化到磁盘\n",
    "\n",
    "# 创建一个本地持久化的向量存储\n",
    "\n",
    "\n",
    "# 现在尝试保存上下文\n",
    "memory.save_context(\n",
    "    {\"input\": \"我最喜欢的颜色是蓝色\"},\n",
    "    {\"output\": \"蓝色是一个很棒的颜色！它让人联想到海洋和天空。\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"我喜欢在周末去爬山\"},\n",
    "    {\"output\": \"爬山是一项很好的活动，既能锻炼身体又能亲近自然。\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\": \"我养了一只叫小花的猫\"},\n",
    "    {\"output\": \"小花是个可爱的名字！猫咪是很好的宠物伴侣。\"}\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个友好的助手，能够记住用户之前提到的信息。\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"human\", \"相关的对话历史：\\n{chat_history}\")\n",
    "])\n",
    "\n",
    "# 创建链\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"deepseek-chat\")\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 测试向量存储记忆\n",
    "response = chain.invoke({\"input\": \"我之前说过我喜欢什么颜色？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
