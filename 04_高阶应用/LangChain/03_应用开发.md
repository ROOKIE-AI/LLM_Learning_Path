# LangChain 应用开发

## 1. 基础应用开发

### 1.1 文本生成应用

#### 1.1.1 文章生成器

```python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# 创建文章生成链
article_prompt = PromptTemplate(
    input_variables=["topic", "style"],
    template="""
    请以{style}的风格写一篇关于{topic}的文章。
    要求：
    1. 结构清晰
    2. 内容充实
    3. 语言流畅
    """
)

article_chain = LLMChain(
    llm=OpenAI(temperature=0.7),
    prompt=article_prompt
)

# 生成文章
article = article_chain.run(
    topic="人工智能发展",
    style="科技"
)
```

#### 1.1.2 代码生成器

```python
# 创建代码生成链
code_prompt = PromptTemplate(
    input_variables=["language", "function"],
    template="""
    请使用{language}编写一个实现{function}的函数。
    要求：
    1. 代码规范
    2. 注释完整
    3. 异常处理
    """
)

code_chain = LLMChain(
    llm=OpenAI(temperature=0.3),
    prompt=code_prompt
)

# 生成代码
code = code_chain.run(
    language="Python",
    function="快速排序算法"
)
```

### 1.2 对话系统开发

#### 1.2.1 聊天机器人

```python
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain

# 创建聊天模型
chat = ChatOpenAI(temperature=0.7)

# 创建记忆
memory = ConversationBufferMemory()

# 创建对话链
conversation = ConversationChain(
    llm=chat,
    memory=memory,
    verbose=True
)

# 进行对话
response1 = conversation.predict(input="你好！")
response2 = conversation.predict(input="请介绍一下你自己")
```

#### 1.2.2 客服系统

```python
from langchain.agents import initialize_agent, Tool
from langchain.tools import DuckDuckGoSearchTool

# 创建工具
search = DuckDuckGoSearchTool()
tools = [
    Tool(
        name="Search",
        func=search.run,
        description="搜索产品信息"
    ),
    Tool(
        name="FAQ",
        func=faq_lookup,
        description="查询常见问题"
    )
]

# 初始化客服代理
agent = initialize_agent(
    tools,
    chat,
    agent="zero-shot-react-description",
    verbose=True
)

# 处理用户问题
response = agent.run("产品价格是多少？")
```

## 2. 高级应用开发

### 2.1 知识库问答系统

#### 2.1.1 文档处理

```python
from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma

# 加载文档
loader = DirectoryLoader(
    './docs',
    glob="**/*.txt"
)
documents = loader.load()

# 分割文档
text_splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
texts = text_splitter.split_documents(documents)

# 创建向量存储
embeddings = OpenAIEmbeddings()
vectorstore = Chroma.from_documents(
    documents=texts,
    embedding=embeddings
)
```

#### 2.1.2 问答链

```python
from langchain.chains import RetrievalQA

# 创建问答链
qa_chain = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=vectorstore.as_retriever()
)

# 回答问题
response = qa_chain.run("什么是机器学习？")
```

### 2.2 智能代理系统

#### 2.2.1 任务规划

```python
from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent
from langchain.prompts import StringPromptTemplate

# 创建任务规划代理
class TaskPlanningAgent:
    def __init__(self):
        self.tools = [
            Tool(
                name="Plan",
                func=self.plan_task,
                description="规划任务步骤"
            ),
            Tool(
                name="Execute",
                func=self.execute_task,
                description="执行任务"
            )
        ]
        
    def plan_task(self, task):
        # 实现任务规划逻辑
        pass
        
    def execute_task(self, plan):
        # 实现任务执行逻辑
        pass
```

#### 2.2.2 工具调用

```python
# 创建自定义工具
def calculator(expression):
    return eval(expression)

tools = [
    Tool(
        name="Calculator",
        func=calculator,
        description="计算数学表达式"
    )
]

# 创建工具调用代理
agent = initialize_agent(
    tools,
    llm,
    agent="zero-shot-react-description"
)

# 执行计算
result = agent.run("计算 23 * 45")
```

## 3. 应用优化

### 3.1 性能优化

#### 3.1.1 响应优化

```python
from langchain.callbacks import get_openai_callback
import asyncio

# 异步调用
async def async_generate():
    async with get_openai_callback() as cb:
        response = await llm.agenerate(["你好"])
    return response

# 批量处理
async def batch_generate(prompts):
    tasks = [async_generate() for _ in prompts]
    return await asyncio.gather(*tasks)
```

#### 3.1.2 缓存优化

```python
from langchain.cache import InMemoryCache
import langchain

# 启用缓存
langchain.cache = InMemoryCache()

# 使用缓存
@langchain.cache
def cached_generate(prompt):
    return llm.generate([prompt])
```

### 3.2 用户体验优化

#### 3.2.1 错误处理

```python
from langchain.exceptions import LangChainError

try:
    response = chain.run(input)
except LangChainError as e:
    # 处理错误
    error_message = f"发生错误：{str(e)}"
    # 返回友好的错误信息
    return {"error": error_message}
```

#### 3.2.2 进度反馈

```python
from langchain.callbacks import get_callback_manager
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# 创建回调管理器
manager = get_callback_manager()
manager.add_handler(StreamingStdOutCallbackHandler())

# 使用回调
chain = LLMChain(
    llm=llm,
    prompt=prompt,
    callbacks=manager
)
```

## 4. 部署与维护

### 4.1 应用部署

#### 4.1.1 环境配置

```python
# requirements.txt
langchain==0.0.200
openai==0.27.0
chromadb==0.3.29
fastapi==0.68.0
uvicorn==0.15.0
```

#### 4.1.2 API服务

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class Query(BaseModel):
    text: str

@app.post("/generate")
async def generate(query: Query):
    response = chain.run(query.text)
    return {"response": response}
```

### 4.2 监控与维护

#### 4.2.1 性能监控

```python
from langchain.callbacks import get_openai_callback

def monitor_performance():
    with get_openai_callback() as cb:
        response = chain.run(input)
        print(f"Token使用量：{cb.total_tokens}")
        print(f"API调用次数：{cb.successful_requests}")
```

#### 4.2.2 日志记录

```python
import logging

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# 记录日志
logger.info("开始处理请求")
try:
    response = chain.run(input)
    logger.info("请求处理成功")
except Exception as e:
    logger.error(f"请求处理失败：{str(e)}")
```