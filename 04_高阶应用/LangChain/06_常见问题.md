# LangChain 常见问题解答

## 1. 基础问题

### 1.1 安装与配置

#### Q: 如何安装 LangChain？

A: 可以通过以下方式安装 LangChain：

```bash
# 使用 pip 安装
pip install langchain

# 安装特定版本
pip install langchain==0.0.200

# 安装所有依赖
pip install "langchain[all]"
```

#### Q: 如何配置 API 密钥？

A: 可以通过以下方式配置 API 密钥：

```python
# 方式 1：环境变量
import os
os.environ["OPENAI_API_KEY"] = "your-api-key"

# 方式 2：直接设置
from langchain.llms import OpenAI
llm = OpenAI(openai_api_key="your-api-key")
```

### 1.2 基本使用

#### Q: 如何创建一个简单的 Chain？

A: 示例代码如下：

```python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate

# 创建 LLM
llm = OpenAI(temperature=0.7)

# 创建提示模板
prompt = PromptTemplate(
    input_variables=["product"],
    template="为 {product} 写一个广告文案"
)

# 创建 Chain
chain = LLMChain(llm=llm, prompt=prompt)

# 运行 Chain
result = chain.run("智能手机")
```

#### Q: 如何处理长文本？

A: 可以使用文本分割器：

```python
from langchain.text_splitter import CharacterTextSplitter

# 创建分割器
text_splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)

# 分割文本
texts = text_splitter.split_text(long_text)
```

## 2. 进阶问题

### 2.1 性能优化

#### Q: 如何提高响应速度？

A: 可以采取以下措施：

```python
# 1. 使用缓存
from langchain.cache import InMemoryCache
langchain.cache = InMemoryCache()

# 2. 异步处理
async def process_request():
    response = await llm.agenerate([prompt])
    return response

# 3. 批量处理
responses = llm.generate(prompts)
```

#### Q: 如何优化内存使用？

A: 可以采取以下措施：

```python
# 1. 使用生成器
def process_documents(documents):
    for doc in documents:
        yield process_document(doc)

# 2. 及时清理内存
import gc
gc.collect()

# 3. 使用流式处理
for chunk in llm.stream(prompt):
    print(chunk)
```

### 2.2 错误处理

#### Q: 如何处理 API 错误？

A: 示例代码如下：

```python
from langchain.llms import OpenAI
from langchain.callbacks import get_openai_callback

try:
    with get_openai_callback() as cb:
        response = llm.generate([prompt])
except Exception as e:
    print(f"API 错误：{str(e)}")
    # 实现错误处理逻辑
```

#### Q: 如何实现重试机制？

A: 示例代码如下：

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
def generate_with_retry(prompt):
    return llm.generate([prompt])
```

## 3. 高级问题

### 3.1 自定义开发

#### Q: 如何创建自定义 LLM？

A: 示例代码如下：

```python
from langchain.llms.base import BaseLLM

class CustomLLM(BaseLLM):
    def __init__(self):
        super().__init__()
    
    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        # 实现自定义逻辑
        return "自定义响应"
    
    @property
    def _llm_type(self) -> str:
        return "custom"
```

#### Q: 如何创建自定义 Chain？

A: 示例代码如下：

```python
from langchain.chains import LLMChain

class CustomChain(LLMChain):
    def __init__(self):
        prompt = PromptTemplate(
            input_variables=["input"],
            template="自定义模板: {input}"
        )
        super().__init__(llm=OpenAI(), prompt=prompt)
    
    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        # 实现自定义逻辑
        return super()._call(inputs)
```

### 3.2 集成问题

#### Q: 如何集成向量数据库？

A: 示例代码如下：

```python
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings

# 创建向量存储
embeddings = OpenAIEmbeddings()
vectorstore = Chroma(
    collection_name="documents",
    embedding_function=embeddings
)

# 添加文档
vectorstore.add_texts(texts)

# 相似度搜索
docs = vectorstore.similarity_search(query)
```

#### Q: 如何集成外部 API？

A: 示例代码如下：

```python
from langchain.tools import Tool
import requests

def search_api(query: str) -> str:
    response = requests.get(f"https://api.example.com/search?q={query}")
    return response.json()

# 创建工具
search_tool = Tool(
    name="search",
    func=search_api,
    description="搜索外部 API"
)

# 使用工具
result = search_tool.run("查询内容")
```

## 4. 最佳实践

### 4.1 开发建议

#### Q: 如何组织项目结构？

A: 建议的项目结构：

```
project/
├── src/
│   ├── config/
│   │   └── settings.py
│   ├── models/
│   │   └── custom_models.py
│   ├── chains/
│   │   └── custom_chains.py
│   └── utils/
│       └── helpers.py
├── tests/
│   └── test_chains.py
├── docs/
│   └── README.md
└── requirements.txt
```

#### Q: 如何编写测试用例？

A: 示例测试代码：

```python
import pytest
from langchain.llms import OpenAI

def test_text_generation():
    llm = OpenAI(temperature=0)
    response = llm.generate(["测试文本"])
    assert len(response.generations[0][0].text) > 0

def test_chain_execution():
    chain = create_test_chain()
    result = chain.run("测试输入")
    assert result is not None
```

### 4.2 部署建议

#### Q: 如何部署 LangChain 应用？

A: 部署步骤：

1. 准备环境：
```bash
# 创建虚拟环境
python -m venv venv
source venv/bin/activate

# 安装依赖
pip install -r requirements.txt
```

2. 配置服务：
```python
# FastAPI 示例
from fastapi import FastAPI
from langchain.llms import OpenAI

app = FastAPI()
llm = OpenAI()

@app.post("/generate")
async def generate_text(prompt: str):
    return llm.generate([prompt])
```

3. 使用 Docker：
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY . .
RUN pip install -r requirements.txt

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### Q: 如何监控应用性能？

A: 监控方案：

```python
# 1. 使用 Prometheus
from prometheus_client import Counter, Histogram

request_counter = Counter(
    'langchain_requests_total',
    'Total number of requests'
)

response_time = Histogram(
    'langchain_response_time_seconds',
    'Response time in seconds'
)

# 2. 使用日志
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# 3. 使用回调
from langchain.callbacks import get_openai_callback

with get_openai_callback() as cb:
    response = llm.generate([prompt])
    print(f"Token 使用量：{cb.total_tokens}")
```