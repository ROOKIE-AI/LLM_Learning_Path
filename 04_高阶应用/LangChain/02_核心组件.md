 # LangChain 核心组件

## 1. Chains（链）

### 1.1 基础链

#### 1.1.1 LLMChain

```python
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate

# 创建 LLM
llm = OpenAI(temperature=0.7)

# 创建提示词模板
prompt = PromptTemplate(
    input_variables=["question"],
    template="请回答以下问题：{question}"
)

# 创建 LLMChain
chain = LLMChain(llm=llm, prompt=prompt)

# 运行链
response = chain.run("什么是人工智能？")
```

#### 1.1.2 SequentialChain

```python
from langchain.chains import SequentialChain

# 创建多个链
chain1 = LLMChain(llm=llm, prompt=prompt1)
chain2 = LLMChain(llm=llm, prompt=prompt2)

# 创建顺序链
sequential_chain = SequentialChain(
    chains=[chain1, chain2],
    input_variables=["input"],
    output_variables=["output1", "output2"]
)
```

### 1.2 高级链

#### 1.2.1 AgentChain

```python
from langchain.agents import initialize_agent, Tool
from langchain.tools import DuckDuckGoSearchTool

# 创建工具
search = DuckDuckGoSearchTool()
tools = [
    Tool(
        name="Search",
        func=search.run,
        description="用于搜索网络信息"
    )
]

# 初始化代理
agent = initialize_agent(
    tools,
    llm,
    agent="zero-shot-react-description",
    verbose=True
)

# 运行代理
agent.run("最新的AI技术发展是什么？")
```

#### 1.2.2 MemoryChain

```python
from langchain.memory import ConversationBufferMemory

# 创建记忆
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# 创建带记忆的链
chain = LLMChain(
    llm=llm,
    prompt=prompt,
    memory=memory
)
```

## 2. Models（模型）

### 2.1 模型类型

#### 2.1.1 LLM

```python
from langchain.llms import OpenAI, HuggingFaceHub

# OpenAI
llm = OpenAI(
    model_name="gpt-3.5-turbo",
    temperature=0.7
)

# HuggingFace
llm = HuggingFaceHub(
    repo_id="google/flan-t5-base",
    model_kwargs={"temperature": 0.7}
)
```

#### 2.1.2 ChatModel

```python
from langchain.chat_models import ChatOpenAI

# 创建聊天模型
chat = ChatOpenAI(
    model_name="gpt-3.5-turbo",
    temperature=0.7
)

# 发送消息
messages = [
    {"role": "system", "content": "你是一个AI助手"},
    {"role": "user", "content": "你好"}
]
response = chat(messages)
```

### 2.2 模型集成

#### 2.2.1 自定义模型

```python
from langchain.llms.base import BaseLLM

class CustomLLM(BaseLLM):
    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:
        # 实现自定义模型逻辑
        return "自定义模型响应"

    @property
    def _llm_type(self) -> str:
        return "custom"
```

## 3. Memory（记忆）

### 3.1 记忆类型

#### 3.1.1 BufferMemory

```python
from langchain.memory import BufferMemory

# 创建缓冲记忆
memory = BufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# 在链中使用
chain = LLMChain(
    llm=llm,
    prompt=prompt,
    memory=memory
)
```

#### 3.1.2 VectorStoreMemory

```python
from langchain.memory import VectorStoreMemory
from langchain.vectorstores import Chroma

# 创建向量存储
vectorstore = Chroma(
    collection_name="memory",
    embedding_function=embeddings
)

# 创建向量存储记忆
memory = VectorStoreMemory(
    vectorstore=vectorstore,
    memory_key="chat_history"
)
```

### 3.2 记忆管理

#### 3.2.1 记忆操作

```python
# 保存记忆
memory.save_context(
    {"input": "用户输入"},
    {"output": "模型输出"}
)

# 加载记忆
memory.load_memory_variables({})

# 清除记忆
memory.clear()
```

## 4. Prompts（提示词）

### 4.1 提示词模板

#### 4.1.1 基础模板

```python
from langchain.prompts import PromptTemplate

# 创建模板
template = PromptTemplate(
    input_variables=["name"],
    template="你好，{name}！"
)

# 格式化模板
formatted = template.format(name="小明")
```

#### 4.1.2 动态模板

```python
from langchain.prompts import FewShotPromptTemplate

# 创建示例
examples = [
    {"question": "2+2", "answer": "4"},
    {"question": "2*3", "answer": "6"}
]

# 创建示例模板
example_template = PromptTemplate(
    input_variables=["question", "answer"],
    template="问题: {question}\n答案: {answer}"
)

# 创建少样本提示词模板
prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_template,
    prefix="请回答以下数学问题",
    suffix="问题: {input}\n答案:",
    input_variables=["input"]
)
```

### 4.2 提示词优化

#### 4.2.1 提示词工程

```python
# 创建结构化提示词
structured_prompt = PromptTemplate(
    input_variables=["context", "question"],
    template="""
    基于以下上下文回答问题：
    
    上下文：{context}
    
    问题：{question}
    
    请提供详细的答案。
    """
)

# 创建条件提示词
conditional_prompt = PromptTemplate(
    input_variables=["type", "content"],
    template="""
    根据类型 {type} 处理以下内容：
    
    内容：{content}
    
    {% if type == "summary" %}
    请提供内容摘要。
    {% else %}
    请提供详细分析。
    {% endif %}
    """
)
```

## 5. 最佳实践

### 5.1 组件使用

- 合理选择链类型
- 优化模型参数
- 管理记忆大小
- 设计有效提示词

### 5.2 性能优化

- 使用异步调用
- 实现缓存机制
- 优化提示词长度
- 控制并发请求

## 6. 常见问题

### 6.1 使用问题

- 链组合问题
- 模型选择问题
- 记忆管理问题
- 提示词设计问题

### 6.2 解决方案

- 使用调试模式
- 优化组件配置
- 实现错误处理
- 添加日志记录